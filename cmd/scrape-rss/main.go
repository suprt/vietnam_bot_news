package main

import (
	"encoding/xml"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"os"
	"regexp"
	"sort"
	"strings"
	"time"

	"gopkg.in/yaml.v3"
)

// RSSFeedInfo —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω–æ–º RSS-—Ñ–∏–¥–µ
type RSSFeedInfo struct {
	URL    string `yaml:"-"`
	Type   string `yaml:"-"` // "main" –∏–ª–∏ "category"
	Source string `yaml:"-"`
}

// SiteConfig –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–∞–π—Ç–∞ –∏–∑ YAML
type SiteConfig struct {
	ID       string   `yaml:"id"`
	Name     string   `yaml:"name"`
	URL      string   `yaml:"url"`
	RSS      string   `yaml:"rss,omitempty"`
	RSSFeeds []string `yaml:"rss_feeds,omitempty"`
	Priority int      `yaml:"priority"`
}

// SitesConfig –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ—Ä–Ω–µ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥
type SitesConfig struct {
	Sites []SiteConfig `yaml:"sites"`
}

// OutputSiteConfig –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
type OutputSiteConfig struct {
	ID       string   `yaml:"id"`
	Name     string   `yaml:"name"`
	URL      string   `yaml:"url"`
	RSSFeeds []string `yaml:"rss_feeds"`
	Priority int      `yaml:"priority"`
}

// OutputConfig –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
type OutputConfig struct {
	Sites []OutputSiteConfig `yaml:"sites"`
}

var (
	visitedRSS  = make(map[string]bool)
	allFoundRSS []RSSFeedInfo
	httpClient  = &http.Client{
		Timeout: 10 * time.Second, // –¢–∞–π–º–∞—É—Ç 10 —Å–µ–∫—É–Ω–¥ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
	}
)

func normalizeURL(rawURL string) string {
	rawURL = strings.TrimSpace(rawURL)
	rawURL = strings.TrimSuffix(rawURL, "/")
	return rawURL
}

func isValidRSSURL(rawURL string) bool {
	urlLower := strings.ToLower(rawURL)
	patterns := []string{"/rss", "/feed", ".rss", ".xml", "/atom"}
	for _, pattern := range patterns {
		if strings.Contains(urlLower, pattern) {
			return true
		}
	}
	return strings.HasSuffix(urlLower, "/rss") || strings.HasSuffix(urlLower, "/feed")
}

func extractRSSFromHTML(htmlContent, baseURL string) map[string]bool {
	rssLinks := make(map[string]bool)

	// –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ RSS-—Å—Å—ã–ª–æ–∫ –≤ HTML
	patterns := []*regexp.Regexp{
		// –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ <link> —Ç–µ–≥–∏ —Å RSS
		regexp.MustCompile(`(?i)<link[^>]*rel=["']alternate["'][^>]*type=["']application/rss\+xml["'][^>]*href=["']([^"']+)["']`),
		regexp.MustCompile(`(?i)<link[^>]*type=["']application/rss\+xml["'][^>]*rel=["']alternate["'][^>]*href=["']([^"']+)["']`),
		// –í—Å–µ href –∞—Ç—Ä–∏–±—É—Ç—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ rss/feed (–≤–∫–ª—é—á–∞—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏)
		regexp.MustCompile(`(?i)href=["']([^"']*(?:rss|feed|\.rss|\.xml)[^"']*)["']`),
		// –°—Å—ã–ª–∫–∏ –≤ <a> —Ç–µ–≥–∞—Ö, –≥–¥–µ href —Å–æ–¥–µ—Ä–∂–∏—Ç rss/feed (–≤–∫–ª—é—á–∞—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ —Ç–∏–ø–∞ /rss/...)
		regexp.MustCompile(`(?i)<a[^>]*href=["']([^"']*(?:rss|feed|/rss/|\.rss)[^"']*)["'][^>]*>`),
		// –°—Å—ã–ª–∫–∏ –≤ <a> —Ç–µ–≥–∞—Ö, –≥–¥–µ —Ç–µ–∫—Å—Ç –∏–ª–∏ title —Å–æ–¥–µ—Ä–∂–∏—Ç RSS/Feed
		regexp.MustCompile(`(?i)<a[^>]*(?:title=["'][^"']*rss[^"']*["']|>.*?rss.*?</a)[^>]*href=["']([^"']+)["']`),
		regexp.MustCompile(`(?i)<a[^>]*href=["']([^"']+)["'][^>]*(?:title=["'][^"']*rss[^"']*["']|>.*?rss.*?</a)`),
		// –°—Å—ã–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ —Å–ø–∏—Å–∫–∞—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, <li><a href="...rss...">)
		regexp.MustCompile(`(?i)<li[^>]*>.*?<a[^>]*href=["']([^"']*(?:rss|feed)[^"']*)["']`),
		// –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ (–¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ RSS-—Å—Å—ã–ª–∫–∏ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã)
		regexp.MustCompile(`(?i)(https?://[^\s<>"']+/(?:rss|feed|category/[^/]+/rss|rss/[^/]+)[^\s<>"']*)`),
	}

	for _, pattern := range patterns {
		matches := pattern.FindAllStringSubmatch(htmlContent, -1)
		for _, match := range matches {
			// –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã –∑–∞—Ö–≤–∞—Ç–∞
			for i := 1; i < len(match); i++ {
				if match[i] != "" {
					href := strings.TrimSpace(match[i])
					// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ —è–∫–æ—Ä–Ω—ã–µ —Å—Å—ã–ª–∫–∏
					if href == "" || strings.HasPrefix(href, "#") {
						continue
					}

					fullURL, err := resolveURL(baseURL, href)
					if err != nil {
						continue
					}

					// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂ –ª–∏ URL –Ω–∞ RSS
					if isValidRSSURL(fullURL) {
						normalized := normalizeURL(fullURL)
						// –ò—Å–∫–ª—é—á–∞–µ–º —Å–∞–º—É –±–∞–∑–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ RSS
						if normalized != normalizeURL(baseURL) || isValidRSSURL(baseURL) {
							rssLinks[normalized] = true
						}
					}
				}
			}
		}
	}

	// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫: –∏—â–µ–º –≤—Å–µ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ URL –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ rss/feed
	urlPattern := regexp.MustCompile(`(?i)(https?://[^\s<>"']+/(?:rss|feed|category/[^/]+/rss|rss/[^/]+|feed/[^/]+)[^\s<>"']*)`)
	urlMatches := urlPattern.FindAllString(htmlContent, -1)
	for _, match := range urlMatches {
		match = strings.TrimSpace(match)
		// –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∑–∞–≤–µ—Ä—à–∞—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã
		match = strings.TrimRight(match, ".,;:)!?\"'")
		if isValidRSSURL(match) {
			normalized := normalizeURL(match)
			if normalized != normalizeURL(baseURL) {
				rssLinks[normalized] = true
			}
		}
	}

	return rssLinks
}

func extractRSSFromXML(xmlContent, baseURL string) map[string]bool {
	rssLinks := make(map[string]bool)

	var feed struct {
		XMLName xml.Name `xml:"rss"`
		Channel struct {
			Link        string `xml:"link"`
			Description string `xml:"description"`
		} `xml:"channel"`
	}

	// –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ RSS
	if err := xml.Unmarshal([]byte(xmlContent), &feed); err == nil {
		if feed.Channel.Link != "" {
			fullURL, err := resolveURL(baseURL, feed.Channel.Link)
			if err == nil && isValidRSSURL(fullURL) {
				rssLinks[normalizeURL(fullURL)] = true
			}
		}
	}

	// –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã <link> –≤ XML
	decoder := xml.NewDecoder(strings.NewReader(xmlContent))
	for {
		token, err := decoder.Token()
		if err == io.EOF {
			break
		}
		if err != nil {
			break
		}
		if se, ok := token.(xml.StartElement); ok {
			if se.Name.Local == "link" {
				var linkText string
				if err := decoder.DecodeElement(&linkText, &se); err == nil {
					linkText = strings.TrimSpace(linkText)
					if linkText != "" {
						fullURL, err := resolveURL(baseURL, linkText)
						if err == nil && isValidRSSURL(fullURL) {
							rssLinks[normalizeURL(fullURL)] = true
						}
					}
				}
			}
		}
	}

	// –ò—â–µ–º URL –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
	urlPattern := regexp.MustCompile(`https?://[^\s<>"']+(?:rss|feed|\.rss|\.xml)`)
	matches := urlPattern.FindAllString(xmlContent, -1)
	for _, match := range matches {
		if isValidRSSURL(match) {
			rssLinks[normalizeURL(match)] = true
		}
	}

	return rssLinks
}

func resolveURL(baseURL, relativeURL string) (string, error) {
	base, err := url.Parse(baseURL)
	if err != nil {
		return "", err
	}
	rel, err := url.Parse(relativeURL)
	if err != nil {
		return "", err
	}
	return base.ResolveReference(rel).String(), nil
}

func fetchRSSPage(rssURL string) (string, string, error) {
	req, err := http.NewRequest("GET", rssURL, nil)
	if err != nil {
		return "", "", err
	}
	req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")

	// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–ª–∏–µ–Ω—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
	client := &http.Client{
		Timeout: 10 * time.Second,
		CheckRedirect: func(req *http.Request, via []*http.Request) error {
			// –†–∞–∑—Ä–µ—à–∞–µ–º –¥–æ 5 —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
			if len(via) >= 5 {
				return fmt.Errorf("stopped after 5 redirects")
			}
			return nil
		},
	}

	resp, err := client.Do(req)
	if err != nil {
		return "", "", err
	}
	defer resp.Body.Close()

	if resp.StatusCode >= 400 {
		// –î–ª—è 403 (Forbidden) –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
		if resp.StatusCode == 403 {
			return "", "", fmt.Errorf("forbidden (403) - –≤–æ–∑–º–æ–∂–Ω–æ, —Å–∞–π—Ç –±–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã")
		}
		return "", "", fmt.Errorf("unexpected status %d", resp.StatusCode)
	}

	content, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", "", err
	}

	contentType := resp.Header.Get("Content-Type")
	finalURL := resp.Request.URL.String()
	if finalURL != rssURL {
		fmt.Printf("    üîÑ –†–µ–¥–∏—Ä–µ–∫—Ç: %s -> %s\n", rssURL, finalURL)
	}

	return string(content), strings.ToLower(contentType), nil
}

func findCategoryRSSFromPage(rssURL string, maxDepth int) map[string]bool {
	if maxDepth <= 0 {
		return make(map[string]bool)
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ—Å–µ—â–∞–ª–∏ –ª–∏ —É–∂–µ —ç—Ç–æ—Ç URL
	alreadyVisited := visitedRSS[rssURL]
	if !alreadyVisited {
		visitedRSS[rssURL] = true
	}

	foundRSS := make(map[string]bool)

	fmt.Printf("  üì° –ü—Ä–æ–≤–µ—Ä—è—é: %s\n", rssURL)

	content, contentType, err := fetchRSSPage(rssURL)
	if err != nil {
		fmt.Fprintf(os.Stderr, "  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ %s: %v\n", rssURL, err)
		return foundRSS
	}

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ
	contentPreview := content[:min(1000, len(content))]
	isXML := strings.Contains(contentType, "xml") || strings.HasPrefix(content, "<?xml") || strings.Contains(contentPreview, "<rss")
	isHTML := strings.Contains(contentType, "html") || strings.Contains(strings.ToLower(contentPreview), "<html") || strings.Contains(strings.ToLower(contentPreview), "<!doctype")

	// –ï—Å–ª–∏ —ç—Ç–æ XML/RSS, –ø–∞—Ä—Å–∏–º –µ–≥–æ
	if isXML && !isHTML {
		xmlRSS := extractRSSFromXML(content, rssURL)
		for k := range xmlRSS {
			foundRSS[k] = true
		}
	}

	// –í–°–ï–ì–î–ê –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫ HTML (–¥–∞–∂–µ –µ—Å–ª–∏ —ç—Ç–æ XML), —Ç–∞–∫ –∫–∞–∫ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∞–π—Ç—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç HTML –Ω–∞ RSS-URL
	// –û—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ URL –≤–µ–¥–µ—Ç –Ω–∞ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º RSS
	htmlRSS := extractRSSFromHTML(content, rssURL)
	if len(htmlRSS) > 0 {
		fmt.Printf("    ‚úÖ –ù–∞–π–¥–µ–Ω–æ %d RSS-—Å—Å—ã–ª–æ–∫\n", len(htmlRSS))
		// –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ RSS-—Å—Å—ã–ª–∫–∏ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
		for k := range htmlRSS {
			foundRSS[k] = true
		}
	}

	// –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –Ω–æ–≤—ã–µ RSS, —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö (—Ç–æ–ª—å–∫–æ –¥–ª—è XML, –Ω–µ –¥–ª—è HTML)
	// –î–ª—è HTML-—Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –¥–µ–ª–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
	newRSS := make(map[string]bool)
	for k := range foundRSS {
		if !visitedRSS[k] {
			newRSS[k] = true
		}
	}

	// –û–¢–ö–õ–Æ–ß–ê–ï–ú —Ä–µ–∫—É—Ä—Å–∏—é –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–ª—è HTML-—Å—Ç—Ä–∞–Ω–∏—Ü, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
	// –î–ª—è XML/RSS —Ç–æ–∂–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é —Å—Ç—Ä–æ–≥–æ
	if len(newRSS) > 0 && maxDepth > 1 && isXML && !isHTML {
		count := 0
		maxRecursive := 3 // –ú–∞–∫—Å–∏–º—É–º 3 —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
		for newURL := range newRSS {
			if count >= maxRecursive {
				break
			}
			recursiveRSS := findCategoryRSSFromPage(newURL, maxDepth-1)
			for k := range recursiveRSS {
				foundRSS[k] = true
			}
			count++
		}
	}

	return foundRSS
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func main() {
	sitesFile := "configs/sites.yaml"

	fmt.Println("üöÄ –ù–∞—á–∏–Ω–∞—é —Å–±–æ—Ä RSS-—Å—Å—ã–ª–æ–∫ –∏–∑ sites.yaml")
	fmt.Println()

	// –ß–∏—Ç–∞–µ–º sites.yaml
	data, err := os.ReadFile(sitesFile)
	if err != nil {
		fmt.Fprintf(os.Stderr, "‚ùå –§–∞–π–ª %s –Ω–µ –Ω–∞–π–¥–µ–Ω: %v\n", sitesFile, err)
		os.Exit(1)
	}

	var config SitesConfig
	if err := yaml.Unmarshal(data, &config); err != nil {
		fmt.Fprintf(os.Stderr, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ %s: %v\n", sitesFile, err)
		os.Exit(1)
	}

	fmt.Printf("üìã –ù–∞–π–¥–µ–Ω–æ %d —Å–∞–π—Ç–æ–≤\n\n", len(config.Sites))

	// –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ RSS-—Å—Å—ã–ª–∫–∏
	for _, site := range config.Sites {
		fmt.Printf("\nüåê %s (%s)\n", site.Name, site.ID)
		fmt.Printf("   URL: %s\n", site.URL)

		// –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ RSS-—Ñ–∏–¥–æ–≤
		rssFeeds := site.RSSFeeds
		if len(rssFeeds) == 0 && site.RSS != "" {
			rssFeeds = []string{site.RSS}
		}

		if len(rssFeeds) == 0 {
			fmt.Println("   ‚ö†Ô∏è  RSS-—Ñ–∏–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
			continue
		}

		var siteRSSList []RSSFeedInfo

		for _, rssURL := range rssFeeds {
			rssURL = normalizeURL(rssURL)
			fmt.Printf("\n   üì∞ –û—Å–Ω–æ–≤–Ω–æ–π RSS: %s\n", rssURL)

			// –ò—â–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ RSS-—Ñ–∏–¥—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
			// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É –¥–æ 1 —É—Ä–æ–≤–Ω—è –¥–ª—è HTML-—Å—Ç—Ä–∞–Ω–∏—Ü, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
			categoryRSS := findCategoryRSSFromPage(rssURL, 1)

			// –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π RSS (–æ–Ω —É–∂–µ –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –ø–æ—Å–µ—â–µ–Ω–Ω—ã–π –≤ findCategoryRSSFromPage)
			// –Ω–æ –º—ã –≤—Å–µ —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ —Å–ø–∏—Å–æ–∫ –∫–∞–∫ "main"
			siteRSSList = append(siteRSSList, RSSFeedInfo{
				URL:    rssURL,
				Type:   "main",
				Source: site.ID,
			})

			// –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ RSS –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–∏—Å–∫–ª—é—á–∞—è –æ—Å–Ω–æ–≤–Ω–æ–π RSS, –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å)
			for catRSS := range categoryRSS {
				// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π RSS, –µ—Å–ª–∏ –æ–Ω –ø–æ–ø–∞–ª –≤ categoryRSS
				if catRSS == rssURL {
					continue
				}
				// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –ª–∏ —É–∂–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω —Ä–∞–Ω–µ–µ)
				alreadyAdded := false
				for _, existing := range siteRSSList {
					if existing.URL == catRSS {
						alreadyAdded = true
						break
					}
				}
				if !alreadyAdded {
					siteRSSList = append(siteRSSList, RSSFeedInfo{
						URL:    catRSS,
						Type:   "category",
						Source: site.ID,
					})
				}
			}
		}

		allFoundRSS = append(allFoundRSS, siteRSSList...)
		fmt.Printf("   ‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ RSS-—Ñ–∏–¥–æ–≤ –¥–ª—è %s: %d\n", site.Name, len(siteRSSList))
	}

	// –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
	fmt.Println("\n" + strings.Repeat("=", 70))
	fmt.Printf("\nüìä –ò–¢–û–ì–û: –ù–∞–π–¥–µ–Ω–æ %d —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö RSS-—Ñ–∏–¥–æ–≤\n\n", len(allFoundRSS))

	// –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–∞–π—Ç–∞–º
	bySite := make(map[string][]RSSFeedInfo)
	for _, rss := range allFoundRSS {
		bySite[rss.Source] = append(bySite[rss.Source], rss)
	}

	// –í—ã–≤–æ–¥–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
	fmt.Println("üìù –ù–∞–π–¥–µ–Ω–Ω—ã–µ RSS-—Ñ–∏–¥—ã –ø–æ —Å–∞–π—Ç–∞–º:")
	fmt.Println()
	for siteID, rssList := range bySite {
		var mainFeeds, categoryFeeds []RSSFeedInfo
		for _, rss := range rssList {
			if rss.Type == "main" {
				mainFeeds = append(mainFeeds, rss)
			} else {
				categoryFeeds = append(categoryFeeds, rss)
			}
		}

		fmt.Printf("  %s:\n", siteID)
		fmt.Printf("    –û—Å–Ω–æ–≤–Ω—ã–µ RSS (%d):\n", len(mainFeeds))
		for _, rss := range mainFeeds {
			fmt.Printf("      - %s\n", rss.URL)
		}

		if len(categoryFeeds) > 0 {
			fmt.Printf("    RSS –∫–∞—Ç–µ–≥–æ—Ä–∏–π (%d):\n", len(categoryFeeds))
			for _, rss := range categoryFeeds {
				fmt.Printf("      - %s\n", rss.URL)
			}
		}
		fmt.Println()
	}

	// –í—ã–≤–æ–¥–∏–º YAML-—Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è sites.yaml
	fmt.Println("\n" + strings.Repeat("=", 70))
	fmt.Println()
	fmt.Println("üí° YAML-—Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è sites.yaml:")
	fmt.Println()
	fmt.Println("sites:")
	for siteID, rssList := range bySite {
		var siteInfo *SiteConfig
		for i := range config.Sites {
			if config.Sites[i].ID == siteID {
				siteInfo = &config.Sites[i]
				break
			}
		}
		if siteInfo == nil {
			continue
		}

		fmt.Printf("  - id: \"%s\"\n", siteID)
		fmt.Printf("    name: \"%s\"\n", siteInfo.Name)
		fmt.Printf("    url: \"%s\"\n", siteInfo.URL)
		fmt.Printf("    rss_feeds:\n")

		// –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ main, –ø–æ—Ç–æ–º category, –ø–æ—Ç–æ–º –ø–æ URL
		sort.Slice(rssList, func(i, j int) bool {
			if rssList[i].Type != rssList[j].Type {
				return rssList[i].Type == "main"
			}
			return rssList[i].URL < rssList[j].URL
		})

		for _, rss := range rssList {
			fmt.Printf("      - \"%s\"\n", rss.URL)
		}
		fmt.Printf("    priority: %d\n", siteInfo.Priority)
		fmt.Println()
	}

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
	outputFile := "scripts/found_rss_feeds.yaml"
	outputConfig := OutputConfig{
		Sites: make([]OutputSiteConfig, 0, len(bySite)),
	}

	for siteID, rssList := range bySite {
		var siteInfo *SiteConfig
		for i := range config.Sites {
			if config.Sites[i].ID == siteID {
				siteInfo = &config.Sites[i]
				break
			}
		}
		if siteInfo == nil {
			continue
		}

		// –°–æ—Ä—Ç–∏—Ä—É–µ–º RSS-—Ñ–∏–¥—ã
		sort.Slice(rssList, func(i, j int) bool {
			if rssList[i].Type != rssList[j].Type {
				return rssList[i].Type == "main"
			}
			return rssList[i].URL < rssList[j].URL
		})

		rssURLs := make([]string, len(rssList))
		for i, rss := range rssList {
			rssURLs[i] = rss.URL
		}

		outputConfig.Sites = append(outputConfig.Sites, OutputSiteConfig{
			ID:       siteID,
			Name:     siteInfo.Name,
			URL:      siteInfo.URL,
			RSSFeeds: rssURLs,
			Priority: siteInfo.Priority,
		})
	}

	// –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∞–π—Ç—ã –ø–æ ID –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
	sort.Slice(outputConfig.Sites, func(i, j int) bool {
		return outputConfig.Sites[i].ID < outputConfig.Sites[j].ID
	})

	outputData, err := yaml.Marshal(outputConfig)
	if err != nil {
		fmt.Fprintf(os.Stderr, "‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ YAML: %v\n", err)
		os.Exit(1)
	}

	header := "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ RSS-—Ñ–∏–¥—ã\n# –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å–∫—Ä–∏–ø—Ç–æ–º cmd/scrape-rss/main.go\n\n"
	if err := os.WriteFile(outputFile, []byte(header+string(outputData)), 0644); err != nil {
		fmt.Fprintf(os.Stderr, "‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ %s\n", outputFile)
}
